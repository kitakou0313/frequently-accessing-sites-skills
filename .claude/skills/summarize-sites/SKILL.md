---
name: summarize-sites
description: Webサイトのリストから最新の記事を要約し、日本語のHTMLレポートとしてエクスポートする。WebFetchツールでサイトを巡回し、記事をまとめます。サイト巡回、記事要約、ニュースまとめを求められた場合に使用する。
compatibility: Uses Chrome MCP for link extraction and WebFetch for article fetching.
---

# summarize-sites

Webサイトのリストから最新N件の記事を要約し、HTMLファイルにエクスポートするスキル。

## 実行手順

### 1. 引数のパース

`$ARGUMENTS` をスペース区切りでトークンに分割し、以下のルールで解釈する:

- `--count=N` または `--count N` → 各サイトから取得する記事数として `count` に設定する（N は正の整数）
- 上記オプション以外のトークンはURLリストとして扱う

**省略時の挙動:**
- `--count` 省略 → `count` = **3**（デフォルト）

**バリデーション:**
- `--count` の値が正の整数でない場合はエラーメッセージを表示して終了する

### 2. URLリストの取得

前ステップでURLトークンが1件以上あれば、それをURLリストとして使用する。

URLトークンが0件の場合、プロジェクトルートの `sites.txt` を `Read` ツールで読み込み、1行1URLとしてURLリストを取得する。空行や `#` で始まるコメント行はスキップする。

URLリストが空の場合はエラーメッセージを表示して終了する。

### 3. 出力ファイルの準備

出力ファイルのパスを決定する: `output/summary-{今日の日付 YYYY-MM-DD}.html`。同名ファイルが存在する場合は上書きする。

`Write` ツールで出力ファイルを以下のヘッダー内容で初期化する:

```html
<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>サイト巡回要約レポート — {今日の日付 YYYY-MM-DD}</title>
</head>
<body>
<h1>サイト巡回要約レポート — {今日の日付 YYYY-MM-DD}</h1>
<p><strong>各サイト取得件数</strong>: {count} 件</p>
<hr>
```

### 4. 各サイトの記事収集と逐次書き出し

各URLに対して以下の手順を実行する:

1. Chrome MCP を使ってサイトのトップURLからリンクURLを収集する。以下の手順で `count` 件に達するまで繰り返す:
   - `mcp__chrome-devtools__navigate_page` でトップURLに遷移する
   - `mcp__chrome-devtools__take_snapshot` でページのスナップショットを取得する
   - スナップショットから記事・投稿・ニュースのリンクURL（相対URLは絶対URLに変換）を抽出し、収集済みリストに追加する
   - 収集済みリスト件数が `count` 件に満たない場合、ページ内に「次のページ」「次へ」「older」「more」「load more」等のリンク一覧ページへ遷移するリンクがあれば、そのリンクに遷移して上記の抽出を繰り返す
   - `count` 件以上収集できたか、次ページへのリンクが見つからなくなった時点で収集を終了する
   - URLリストが `count` 件収集できたら、Chrome MCPで取得したページ情報（スナップショット等）はコンテキストから不要になるため、以降の処理では参照しない（メモリ節約のため意識的に破棄する）

2. 抽出した記事URLのうち**先頭から `count` 件のみ**を処理し、それ以降はスキップする。**各記事を処理するたびに即座にファイルへ追記する**:
   - 最初の記事を処理する前に、以下のサイトヘッダーを `Edit` ツールでファイルへ追記する:
     ```html
     <h2><a href="{URL}">{サイト名}</a></h2>
     ```
   - `WebFetch` ツールで記事URLを取得する。promptには「以下の情報をJSON形式で抽出してください: title（記事タイトル）, date（公開日 YYYY-MM-DD形式、不明なら"不明"）, summary（記事全体の内容の網羅的な要約、2〜3文。**必ず日本語で生成**）」と指定する
   - レスポンスから title, date, summary を読み取る
   - **1記事分の情報が揃ったら即座に** `Edit` ツールで以下のHTML形式をファイルへ追記する:
     ```html
     <article>
       <h3><a href="{記事URL}">{記事タイトル}</a></h3>
       <ul>
         <li><strong>日付</strong>: {公開日}</li>
         <li><strong>要約</strong>: {要約文}</li>
       </ul>
     </article>
     ```

3. そのサイトの全記事追記が完了したら、区切り線 `<hr>` を `Edit` ツールでファイルへ追記する。

4. 全サイトの処理が完了したら、以下の閉じタグを `Edit` ツールでファイルへ追記する:
   ```html
   </body>
   </html>
   ```

記事が0件だったサイトには `<p>記事が見つかりませんでした。</p>` と記載して追記する。
`WebFetch` がエラーになった場合は `<p>サイトの取得に失敗しました。</p>` と記載して追記し、次のサイトに進む。

### 5. 生成したファイルをクラウドに保存
生成したファイルのコピーを以下のディレクトリに保存する。
- "$HOME/Library/Mobile Documents/com~apple~CloudDocs/docs"

### 6. 完了報告

保存したファイルのパスをユーザーに報告する。各サイト取得件数（count）、対象サイト数、取得成功数、記事総数も合わせて報告する。
