---
name: summarize-sites
description: Webサイトのリストから最新の記事を要約し、Markdownレポートとしてエクスポートする。WebFetchツールでサイトを巡回し、記事をまとめます。サイト巡回、記事要約、ニュースまとめを求められた場合に使用する。
compatibility: Uses WebFetch tool for page fetching.
---

# summarize-sites

Webサイトのリストから最新N件の記事を要約し、Markdownファイルにエクスポートするスキル。

## 実行手順

### 1. 引数のパース

`$ARGUMENTS` をスペース区切りでトークンに分割し、以下のルールで解釈する:

- `--count=N` または `--count N` → 各サイトから取得する記事数として `count` に設定する（N は正の整数）
- 上記オプション以外のトークンはURLリストとして扱う

**省略時の挙動:**
- `--count` 省略 → `count` = **3**（デフォルト）

**バリデーション:**
- `--count` の値が正の整数でない場合はエラーメッセージを表示して終了する

### 2. URLリストの取得

前ステップでURLトークンが1件以上あれば、それをURLリストとして使用する。

URLトークンが0件の場合、プロジェクトルートの `sites.txt` を `Read` ツールで読み込み、1行1URLとしてURLリストを取得する。空行や `#` で始まるコメント行はスキップする。

URLリストが空の場合はエラーメッセージを表示して終了する。

### 3. 出力ファイルの準備

出力ファイルのパスを決定する: `output/summary-{今日の日付 YYYY-MM-DD}.md`。同名ファイルが存在する場合は上書きする。

`Write` ツールで出力ファイルを以下のヘッダー内容で初期化する:

```markdown
# サイト巡回要約レポート — {今日の日付 YYYY-MM-DD}

**各サイト取得件数**: {count} 件

---
```

### 4. 各サイトの記事収集と逐次書き出し

各URLに対して以下の手順を実行し、**1サイト処理が完了するたびに即座にファイルへ追記**する:

1. `WebFetch` ツールでサイトのトップURLを取得する。promptには「記事・投稿・ニュースのリンクURLを最大10件抽出してください。相対URLは絶対URLに変換してください。」と指定する

2. 抽出した記事URLのうち**先頭から `count` 件のみ**を処理し、それ以降はスキップする:
   - `WebFetch` ツールで記事URLを取得する。promptには「以下の情報をJSON形式で抽出してください: title（記事タイトル）, date（公開日 YYYY-MM-DD形式、不明なら"不明"）, summary（記事全体の内容の網羅的な要約、2〜3文）」と指定する
   - レスポンスから title, date, summary を読み取る

3. 1サイト分の情報が揃ったら、以下のMarkdown形式で**すぐにファイルへ追記**する（`Edit` ツールを使用）:

```markdown
## {サイト名} ({URL})

### {記事タイトル1}
- **日付**: {公開日}
- **要約**: {要約文}
- **リンク**: {記事URL}

### {記事タイトル2}
- **日付**: {公開日}
- **要約**: {要約文}
- **リンク**: {記事URL}

---
```

記事が0件だったサイトには「記事が見つかりませんでした。」と記載して追記する。
`WebFetch` がエラーになった場合は「サイトの取得に失敗しました。」と記載して追記し、次のサイトに進む。

### 5. 完了報告

保存したファイルのパスをユーザーに報告する。各サイト取得件数（count）、対象サイト数、取得成功数、記事総数も合わせて報告する。
