---
name: summarize-sites
description: Webサイトのリストから最新の記事を要約し、Markdownレポートとしてエクスポートする。WebFetchツールでサイトを巡回し、記事をまとめます。サイト巡回、記事要約、ニュースまとめを求められた場合に使用する。
compatibility: Uses WebFetch tool for page fetching.
---

# summarize-sites

Webサイトのリストから最新の5記事を要約し、Markdownファイルにエクスポートするスキル。

## 実行手順

### 1. URLリストの取得

`$ARGUMENTS` が空でない場合、スペース区切りでURLリストとして使用する。

`$ARGUMENTS` が空の場合、プロジェクトルートの `sites.txt` を `Read` ツールで読み込み、1行1URLとしてURLリストを取得する。空行や `#` で始まるコメント行はスキップする。

URLリストが空の場合はエラーメッセージを表示して終了する。

### 2. 出力ファイルの準備

`Bash` で `output/` ディレクトリを作成する（`mkdir output`）。

その後、出力ファイルのパスを決定する: `output/summary-{今日の日付 YYYY-MM-DD}.md`。同名ファイルが存在する場合は `output/summary-{今日の日付 YYYY-MM-DD}-1.md` のように連番を付ける。

`Write` ツールで出力ファイルを以下のヘッダー内容で初期化する:

```markdown
# サイト巡回要約レポート — {今日の日付 YYYY-MM-DD}

---
```

### 3. 各サイトの記事収集と逐次書き出し

各URLに対して以下の手順を実行し、**1サイト処理が完了するたびに即座にファイルへ追記**する:

1. `WebFetch` ツールでサイトのトップURLを取得する。promptには「記事・投稿・ニュースのリンクURLを最大5件抽出してください。相対URLは絶対URLに変換してください。」と指定する
2. 抽出した各記事URLに対して以下を繰り返す:
   - `WebFetch` ツールで記事URLを取得する。promptには「以下の情報をJSON形式で抽出してください: title（記事タイトル）, date（公開日 YYYY-MM-DD形式、不明なら"不明"）, summary（記事全体の内容の網羅的な要約、2〜3文）」と指定する
   - レスポンスから title, date, summary を読み取る

3. 1サイト分の情報が揃ったら、以下のMarkdown形式で**すぐにファイルへ追記**する（`Edit` ツールを使用）:

```markdown
## {サイト名} ({URL})

### {記事タイトル1}
- **日付**: {公開日}
- **要約**: {要約文}
- **リンク**: {記事URL}

### {記事タイトル2}
- **日付**: {公開日}
- **要約**: {要約文}
- **リンク**: {記事URL}

---
```

記事が見つからなかったサイトには「該当期間の記事は見つかりませんでした。」と記載して追記する。
`WebFetch` がエラーになった場合は「サイトの取得に失敗しました。」と記載して追記し、次のサイトに進む。

### 4. 完了報告

保存したファイルのパスをユーザーに報告する。対象サイト数、取得成功数、記事総数も合わせて報告する。
